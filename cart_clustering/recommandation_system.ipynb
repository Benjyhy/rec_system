{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48cc0f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version:  1.23.4\n",
      "Pickle version:  4.0\n"
     ]
    }
   ],
   "source": [
    "# Import all necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "print('NumPy version: ', np.__version__)\n",
    "import pickle\n",
    "print('Pickle version: ', pickle.format_version)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60f13275",
   "metadata": {},
   "outputs": [],
   "source": [
    "carts = pd.read_csv('all_carts_encoded.csv')\n",
    "tickets = np.unique(carts['TICKET_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "17033ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickets_items_list = pickle.load(open('items_list_for_ticket.txt', 'rb'))\n",
    "def prepSparseMatrix(list_of_str):\n",
    "    cv = CountVectorizer(token_pattern = r'[^\\,\\ ]+', lowercase = False)\n",
    "    sparseMatrix = cv.fit_transform(list_of_str)\n",
    "    return sparseMatrix, cv.get_feature_names_out()\n",
    "sparseMatrix, feature_names = prepSparseMatrix(tickets_items_list)\n",
    "df_sparseMatrix = pd.DataFrame.sparse.from_spmatrix(sparseMatrix, index = tickets, columns = feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d508de41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = pickle.load(open(f'models/kmeans/0.pkl', 'rb'))\n",
    "clusters = model.fit_predict(sparseMatrix)\n",
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "587975dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2734831</th>\n",
       "      <th>2734832</th>\n",
       "      <th>2734833</th>\n",
       "      <th>2734834</th>\n",
       "      <th>2734835</th>\n",
       "      <th>2734836</th>\n",
       "      <th>2734837</th>\n",
       "      <th>2734838</th>\n",
       "      <th>2734839</th>\n",
       "      <th>2734840</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TICKET_ID</th>\n",
       "      <td>32931447</td>\n",
       "      <td>32931448</td>\n",
       "      <td>32931451</td>\n",
       "      <td>32931452</td>\n",
       "      <td>32931453</td>\n",
       "      <td>32931454</td>\n",
       "      <td>32931455</td>\n",
       "      <td>32931456</td>\n",
       "      <td>32931461</td>\n",
       "      <td>32931462</td>\n",
       "      <td>...</td>\n",
       "      <td>36529856</td>\n",
       "      <td>36529857</td>\n",
       "      <td>36529858</td>\n",
       "      <td>36529859</td>\n",
       "      <td>36529860</td>\n",
       "      <td>36529861</td>\n",
       "      <td>36529862</td>\n",
       "      <td>36529863</td>\n",
       "      <td>36529864</td>\n",
       "      <td>36529865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 2734841 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5        \\\n",
       "TICKET_ID  32931447  32931448  32931451  32931452  32931453  32931454   \n",
       "Cluster           0         0         0         0         0         0   \n",
       "\n",
       "            6         7         8         9        ...   2734831   2734832  \\\n",
       "TICKET_ID  32931455  32931456  32931461  32931462  ...  36529856  36529857   \n",
       "Cluster           7         0         0         0  ...         0         0   \n",
       "\n",
       "            2734833   2734834   2734835   2734836   2734837   2734838  \\\n",
       "TICKET_ID  36529858  36529859  36529860  36529861  36529862  36529863   \n",
       "Cluster           0         0         0         0         0         0   \n",
       "\n",
       "            2734839   2734840  \n",
       "TICKET_ID  36529864  36529865  \n",
       "Cluster           0         0  \n",
       "\n",
       "[2 rows x 2734841 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display each ticket and its corresponding cluster (need clusters given my fit_transform a model)\n",
    "tickets_cluster = pd.DataFrame(np.concatenate((tickets.reshape(-1,1), clusters.reshape(-1,1)), axis = 1), columns = ['TICKET_ID', 'Cluster'])\n",
    "tickets_cluster.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05e9bc72",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [21], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m         each_cluster_libelles\u001b[38;5;241m.\u001b[39mappend(pd\u001b[38;5;241m.\u001b[39mDataFrame(tickets_libelles_counts, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLIBELLE_ENCODED\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCount\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39msort_values(by \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCount\u001b[39m\u001b[38;5;124m'\u001b[39m], ascending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m each_cluster_libelles\n\u001b[0;32m---> 15\u001b[0m cluster_libelles \u001b[38;5;241m=\u001b[39m \u001b[43mclustersLibelles\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtickets_cluster\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcarts\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [21], line 9\u001b[0m, in \u001b[0;36mclustersLibelles\u001b[0;34m(tickets_cluster, tickets_data)\u001b[0m\n\u001b[1;32m      7\u001b[0m tickets_libelles_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ticket \u001b[38;5;129;01min\u001b[39;00m tickets_list:    \n\u001b[0;32m----> 9\u001b[0m     tickets_libelles_list\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtickets_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtickets_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTICKET_ID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mticket\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLIBELLE_ENCODED\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     10\u001b[0m tickets_libelles_counts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n\u001b[1;32m     11\u001b[0m tickets_libelles_counts\u001b[38;5;241m.\u001b[39mextend([[libelle, tickets_libelles_list\u001b[38;5;241m.\u001b[39mcount(libelle)] \u001b[38;5;28;01mfor\u001b[39;00m libelle \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39munique(tickets_libelles_list)])\n",
      "File \u001b[0;32m~/Dev-Lab/DAT_901/DAT901_PY_ENV/lib/python3.8/site-packages/dask/dataframe/core.py:3785\u001b[0m, in \u001b[0;36mSeries.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3782\u001b[0m \u001b[38;5;129m@derived_from\u001b[39m(pd\u001b[38;5;241m.\u001b[39mSeries)\n\u001b[1;32m   3783\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   3784\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnpartitions):\n\u001b[0;32m-> 3785\u001b[0m         s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_partition\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3786\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m s\n",
      "File \u001b[0;32m~/Dev-Lab/DAT_901/DAT901_PY_ENV/lib/python3.8/site-packages/dask/base.py:315\u001b[0m, in \u001b[0;36mDaskMethodsMixin.compute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \n\u001b[1;32m    294\u001b[0m \u001b[38;5;124;03m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;124;03m    dask.base.compute\u001b[39;00m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 315\u001b[0m     (result,) \u001b[38;5;241m=\u001b[39m \u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Dev-Lab/DAT_901/DAT901_PY_ENV/lib/python3.8/site-packages/dask/base.py:600\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    597\u001b[0m     keys\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_keys__())\n\u001b[1;32m    598\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[0;32m--> 600\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[0;32m~/Dev-Lab/DAT_901/DAT901_PY_ENV/lib/python3.8/site-packages/dask/threaded.py:89\u001b[0m, in \u001b[0;36mget\u001b[0;34m(dsk, keys, cache, num_workers, pool, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pool, multiprocessing\u001b[38;5;241m.\u001b[39mpool\u001b[38;5;241m.\u001b[39mPool):\n\u001b[1;32m     87\u001b[0m         pool \u001b[38;5;241m=\u001b[39m MultiprocessingPoolExecutor(pool)\n\u001b[0;32m---> 89\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mget_async\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_max_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43mget_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_thread_get_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpack_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpack_exception\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# Cleanup pools associated to dead threads\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pools_lock:\n",
      "File \u001b[0;32m~/Dev-Lab/DAT_901/DAT901_PY_ENV/lib/python3.8/site-packages/dask/local.py:500\u001b[0m, in \u001b[0;36mget_async\u001b[0;34m(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwaiting\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mready\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrunning\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    499\u001b[0m     fire_tasks(chunksize)\n\u001b[0;32m--> 500\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, res_info, failed \u001b[38;5;129;01min\u001b[39;00m \u001b[43mqueue_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mresult():\n\u001b[1;32m    501\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m failed:\n\u001b[1;32m    502\u001b[0m             exc, tb \u001b[38;5;241m=\u001b[39m loads(res_info)\n",
      "File \u001b[0;32m~/Dev-Lab/DAT_901/DAT901_PY_ENV/lib/python3.8/site-packages/dask/local.py:137\u001b[0m, in \u001b[0;36mqueue_get\u001b[0;34m(q)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mqueue_get\u001b[39m(q):\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.8/queue.py:170\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_qsize():\n\u001b[0;32m--> 170\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be a non-negative number\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.8/threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 302\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# For each cluster, how many times do we find each libelle\n",
    "def clustersLibelles(tickets_cluster, tickets_data):\n",
    "    clusters = list(tickets_cluster['Cluster'])\n",
    "    each_cluster_libelles = list()\n",
    "    for i in range(len(np.unique(clusters))):\n",
    "        tickets_list = list(tickets_cluster[tickets_cluster['Cluster'] == i]['TICKET_ID'])\n",
    "        tickets_libelles_list = list()\n",
    "        for ticket in tickets_list:    \n",
    "            tickets_libelles_list.extend(list(tickets_data[tickets_data['TICKET_ID'] == ticket]['LIBELLE_ENCODED']))\n",
    "        tickets_libelles_counts = list()\n",
    "        tickets_libelles_counts.extend([[libelle, tickets_libelles_list.count(libelle)] for libelle in np.unique(tickets_libelles_list)])\n",
    "        each_cluster_libelles.append(pd.DataFrame(tickets_libelles_counts, columns=['LIBELLE_ENCODED', 'Count']).sort_values(by = ['Count'], ascending = False).reset_index(drop=True))\n",
    "    return each_cluster_libelles\n",
    "\n",
    "cluster_libelles = clustersLibelles(tickets_cluster, carts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f741277",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cluster_libelles' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [27], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# For cluster 1, libelle [LIBELLE_ENCODED] is present [Count] times\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mcluster_libelles\u001b[49m[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mT\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cluster_libelles' is not defined"
     ]
    }
   ],
   "source": [
    "# For cluster 1, libelle [LIBELLE_ENCODED] is present [Count] times\n",
    "cluster_libelles[1].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "660dd41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tickets in Cluster 0 ->  2227309\n",
      "Tickets in Cluster 1 ->  65794\n",
      "Tickets in Cluster 2 ->  45575\n",
      "Tickets in Cluster 3 ->  18316\n",
      "Tickets in Cluster 4 ->  129868\n",
      "Tickets in Cluster 5 ->  48830\n",
      "Tickets in Cluster 6 ->  144624\n",
      "Tickets in Cluster 7 ->  54525\n",
      "Total number of tickets : 2734841\n"
     ]
    }
   ],
   "source": [
    "# How many different tickets are in each cluster ?\n",
    "# Also check that the sum of the nb of tickets in each cluster == the total number of tickets at start\n",
    "total_nb_tickets = 0\n",
    "for i in range(8):\n",
    "    len_tickets = tickets_cluster[tickets_cluster['Cluster'] == i].shape[0]\n",
    "    total_nb_tickets += len_tickets\n",
    "    print('Tickets in Cluster ' + str(i) + ' -> ', len_tickets) \n",
    "print(f\"Total number of tickets : {total_nb_tickets}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "29802a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([32946317, 33182830, 33577174, 34015044, 34398198, 34665272,\n",
       "       35017400, 35221068, 35546515, 35703330, 35816290, 35998180,\n",
       "       36061723, 36315860, 36434434])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all the tickets belonging to a certain client (by his id)\n",
    "tickets_of_clients = pd.read_csv('KaDo.csv', usecols = ['TICKET_ID', 'CLI_ID'])\n",
    "def tickets_of_a_client(client_id):\n",
    "    tickets_df = tickets_of_clients[tickets_of_clients['CLI_ID'] == client_id]\n",
    "    return tickets_df['TICKET_ID'].unique()    \n",
    "    \n",
    "analyzed_client_tickets = tickets_of_a_client(941958669)\n",
    "analyzed_client_tickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1306e78f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all the clusters of a specific client thanks to his former tickets\n",
    "def clusters_of_a_client(tickets):\n",
    "    client_clusters = list()\n",
    "    for ticket_id in tickets:\n",
    "        current_cluster = tickets_cluster[tickets_cluster['TICKET_ID'] == ticket_id]['Cluster'].values[0]\n",
    "        if current_cluster not in client_clusters:\n",
    "            client_clusters.append(current_cluster)\n",
    "    return client_clusters\n",
    "\n",
    "analyzed_client_clusters = clusters_of_a_client(analyzed_client_tickets)\n",
    "analyzed_client_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8fc656e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[187,\n",
       " 897,\n",
       " 169,\n",
       " 1305,\n",
       " 600,\n",
       " 897,\n",
       " 527,\n",
       " 18,\n",
       " 945,\n",
       " 1259,\n",
       " 31,\n",
       " 897,\n",
       " 1259,\n",
       " 1334,\n",
       " 897,\n",
       " 35,\n",
       " 1305,\n",
       " 171,\n",
       " 920,\n",
       " 1303,\n",
       " 1317,\n",
       " 899,\n",
       " 667]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bought_items(tickets):\n",
    "    bought_items = list()\n",
    "    for ticket_id in tickets:\n",
    "        libelles_serie = df_sparseMatrix.loc[ticket_id]\n",
    "        for item_id in list(libelles_serie[libelles_serie==1].index):\n",
    "            bought_items.append(item_id)\n",
    "    return list(map(int,bought_items))\n",
    "            \n",
    "analyzed_client_bought_items = bought_items(analyzed_client_tickets)\n",
    "analyzed_client_bought_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2c9aeef4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cluster_libelles' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [33], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m                 items_contained_in_clusters\u001b[38;5;241m.\u001b[39mappend(item)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m items_contained_in_clusters\n\u001b[0;32m---> 10\u001b[0m items_in_clusters \u001b[38;5;241m=\u001b[39m \u001b[43mitems_contained_in_clusters\u001b[49m\u001b[43m(\u001b[49m\u001b[43manalyzed_client_clusters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m items_in_clusters\n",
      "Cell \u001b[0;32mIn [33], line 4\u001b[0m, in \u001b[0;36mitems_contained_in_clusters\u001b[0;34m(clusters)\u001b[0m\n\u001b[1;32m      2\u001b[0m items_contained_in_clusters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cluster \u001b[38;5;129;01min\u001b[39;00m clusters:\n\u001b[0;32m----> 4\u001b[0m     items \u001b[38;5;241m=\u001b[39m \u001b[43mcluster_libelles\u001b[49m[cluster][cluster_libelles[cluster][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCount\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m500\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLIBELLE_ENCODED\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m items:\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m item \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m items_contained_in_clusters:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cluster_libelles' is not defined"
     ]
    }
   ],
   "source": [
    "def items_contained_in_clusters(clusters):\n",
    "    items_contained_in_clusters = list()\n",
    "    for cluster in clusters:\n",
    "        items = cluster_libelles[cluster][cluster_libelles[cluster]['Count'] > 500]['LIBELLE_ENCODED'].values\n",
    "        for item in items:\n",
    "            if item not in items_contained_in_clusters:\n",
    "                items_contained_in_clusters.append(item)\n",
    "    return items_contained_in_clusters\n",
    "\n",
    "items_in_clusters = items_contained_in_clusters(analyzed_client_clusters)\n",
    "items_in_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9feb5186",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'analyzed_client_bought_items' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m             suggested_items\u001b[39m.\u001b[39mappend(item)\n\u001b[1;32m      6\u001b[0m     \u001b[39mreturn\u001b[39;00m suggested_items\n\u001b[0;32m----> 8\u001b[0m suggested_items \u001b[39m=\u001b[39m items_suggestion(analyzed_client_bought_items, items_in_clusters)\n\u001b[1;32m      9\u001b[0m suggested_items\n",
      "\u001b[0;31mNameError\u001b[0m: name 'analyzed_client_bought_items' is not defined"
     ]
    }
   ],
   "source": [
    "def items_suggestion(bought_items, items_in_clusters):\n",
    "    suggested_items = list()\n",
    "    for item in items_in_clusters:\n",
    "        if item not in bought_items:\n",
    "            suggested_items.append(item)\n",
    "    return suggested_items\n",
    "\n",
    "suggested_items = items_suggestion(analyzed_client_bought_items, items_in_clusters)\n",
    "suggested_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "484c92de",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'decoded_suggested_items' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Decode labels so we can read the\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m decoded_suggested_items\u001b[39m.\u001b[39mappend(le\u001b[39m.\u001b[39minverse_transform(si))\n\u001b[1;32m      3\u001b[0m decoded_suggested_items\n",
      "\u001b[0;31mNameError\u001b[0m: name 'decoded_suggested_items' is not defined"
     ]
    }
   ],
   "source": [
    "# Decode labels so we can read the\n",
    "decoded_suggested_items.append(le.inverse_transform(si))\n",
    "decoded_suggested_items"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "512c3e2ce116c7f289a48e5c2e62b1682dc65dfed1b1c2257aba7fe84a3827e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
